@article{aiken2008,
  title = {Doctoral Training in Statistics, Measurement, and Methodology in Psychology: {{Replication}} and Extension of {{Aiken}}, {{West}}, {{Sechrest}}, and {{Reno}}'s (1990) Survey of {{PhD}} Programs in {{North America}}},
  author = {Aiken, Leona S and West, Stephen G and Millsap, Roger E},
  year = 2008,
  journal = {American Psychologist},
  volume = {63},
  number = {1},
  pages = {32--50},
  issn = {0003-066X},
  abstract = {In a survey of all PhD programs in psychology in the United States and Canada, the authors documented the quantitative methodology curriculum (statistics, measurement, and research design) to examine the extent to which innovations in quantitative methodology have diffused into the training of PhDs in psychology. In all, 201 psychology PhD programs (86\%) participated. This survey replicated and extended a previous survey (L. S. Aiken, S. G. West, L. B. Sechrest, \& R. R. Reno, 1990), permitting examination of curriculum development. Most training supported laboratory and not field research. The median of 1.6 years of training in statistics and measurement was mainly devoted to the modally 1-year introductory statistics course, leaving little room for advanced study. Curricular enhancements were noted in statistics and to a minor degree in measurement. Additional coverage of both fundamental and innovative quantitative methodology is needed. The research design curriculum has largely stagnated, a cause for great concern. Elite programs showed no overall advantage in quantitative training. Forces that support curricular innovation are characterized. Human capital challenges to quantitative training, including recruiting and supporting young quantitative faculty, are discussed. Steps must be taken to bring innovations in quantitative methodology into the curriculum of PhD programs in psychology.}
}

@inproceedings{babuji2016,
  title = {A Secure Data Enclave and Analytics Platform for Social Scientists},
  booktitle = {Proceedings of the 12th {{IEEE International Conference}} on E-{{Science}}},
  author = {Babuji, Yadu N. and Chard, Kyle and Gerow, Aaron and Duede, Eamon},
  year = 2016,
  pages = {337--342},
  urldate = {2025-10-22},
  abstract = {Data-driven research is increasingly ubiquitous and data itself is a defining asset for researchers, particularly in the computational social sciences and humanities. Entire careers and research communities are built around valuable, proprietary or sensitive datasets. However, many existing computation resources fail to support secure and cost-effective storage of data while also enabling secure and flexible analysis of the data. To address these needs we present CLOUD KOTTA, a cloud-based architecture for the secure management and analysis of social science data. CLOUD KOTTA leverages reliable, secure, and scalable cloud resources to deliver capabilities to users, and removes the need for users to manage complicated infrastructure. CLOUD KOTTA implements automated, cost-aware models for efficiently provisioning tiered storage and automatically scaled compute resources. CLOUD KOTTA has been used in production for several months and currently manages approximately 10TB of data and has been used to process more than 5TB of data with over 75,000 CPU hours. It has been used for a broad variety of text analysis workflows, matrix factorization, and various machine learning algorithms, and more broadly, it supports fast, secure and cost-effective research.},
  keywords = {Cloud computing,Computational modeling,Computer architecture,Data models,Databases,Production,Reliability}
}

@article{bazzoli2022,
  title = {Open Science and Epistemic Pluralism: {{A}} Tale of Many Perils and Some Opportunities},
  shorttitle = {Open Science and Epistemic Pluralism},
  author = {Bazzoli, Andrea},
  year = 2022,
  month = dec,
  journal = {Industrial and Organizational Psychology},
  volume = {15},
  number = {4},
  pages = {525--528},
  issn = {1754-9426, 1754-9434},
  urldate = {2025-10-22},
  langid = {english}
}

@article{boettiger2017,
  title = {An Introduction to Rocker: Docker Containers for {{R}}},
  shorttitle = {An Introduction to Rocker},
  author = {Boettiger, Carl and Eddelbuettel, Dirk},
  year = 2017,
  journal = {The R Journal},
  volume = {9},
  number = {2},
  pages = {527--536},
  issn = {2073-4859},
  urldate = {2024-11-02},
  langid = {english}
}

@article{bruss1993,
  title = {Graduate School Training in Psychology: {{Its}} Impact upon the Development of Professional Identity},
  shorttitle = {Graduate School Training in Psychology},
  author = {Bruss, Katherine V. and Kopala, Mary},
  year = 1993,
  journal = {Psychotherapy: Theory, Research, Practice, Training},
  volume = {30},
  number = {4},
  pages = {685--691},
  issn = {1939-1536},
  abstract = {Synthesizes information from the published literature and suggests a developmental framework for understanding the development of professional identity among psychology trainees. The authors propose that graduate training in psychology may be viewed in terms of a professional infancy. Transformations students go through may be seen to parallel several developmental milestones in the first year of life as outlined by D. W. Winnicott (1965). The training institution is viewed as a holding environment that is responsible for nurturing healthy development. Obstacles that hinder students' growth within this environment are explored, and suggestions for facilitating development of professional identity are provided. (PsycInfo Database Record (c) 2025 APA, all rights reserved)},
  keywords = {Graduate Psychology Education,Professional Identity}
}

@book{bryan2016,
  title = {Happy {{Git}} and {{GitHub}} for the {{useR}}},
  author = {Bryan, Jenny},
  year = 2016,
  url = {https://happygitwithr.com/}
}

@book{chacon2014,
  title = {Pro {{Git}}},
  author = {Chacon, S and Straub, B},
  year = 2014,
  edition = {2nd},
  publisher = {Apress}
}

@article{chan2023,
  title = {Rang: {{Reconstructing}} Reproducible {{R}} Computational Environments},
  shorttitle = {Rang},
  author = {Chan, Chung-hong and Schoch, David},
  year = 2023,
  journal = {PLOS ONE},
  volume = {18},
  number = {6},
  pages = {e0286761},
  issn = {1932-6203},
  urldate = {2025-10-23},
  abstract = {A complete declarative description of the computational environment is usually missing when researchers share their materials. Without such description, software obsolescence and missing system components can jeopardize computational reproducibility in the future, even when data and computer code are available. The R package rang is a complete solution for generating the declarative description for other researchers to automatically reconstruct the computational environment at a specific time point. The reconstruction process, based on Docker, has been tested for R code as old as 2001. The declarative description generated by rang satisfies the definition of a reproducible research compendium and can be shared as such. In this contribution, we show how rang can be used to make otherwise unexecutable code, spanning fields such as computational social science and bioinformatics, executable again. We also provide instructions on how to use rang to construct reproducible and shareable research compendia of current research. The package is currently available from CRAN (https://cran.r-project.org/web/packages/rang/index.html) and GitHub (https://github.com/chainsawriot/rang).},
  langid = {english},
  keywords = {Archaeology,Bioinformatics,Computer software,Metaanalysis,Operating systems,Programming languages,Reproducibility,Software tools}
}

@article{cruess2015,
  title = {A Schematic Representation of the Professional Identity Formation and Socialization of Medical Students and Residents: A Guide for Medical Educators},
  shorttitle = {A Schematic Representation of the Professional Identity Formation and Socialization of Medical Students and Residents},
  author = {Cruess, Richard L. and Cruess, Sylvia R. and Boudreau, J. Donald and Snell, Linda and Steinert, Yvonne},
  year = 2015,
  journal = {Academic Medicine},
  volume = {90},
  number = {6},
  pages = {718},
  issn = {1040-2446},
  urldate = {2025-10-22},
  abstract = {Recent calls to focus on identity formation in medicine propose that educators establish as a goal of medical education the support and guidance of students and residents as they develop their professional identity. Those entering medical school arrive with a personal identity formed since birth. As they proceed through the educational continuum, they successively develop the identity of a medical student, a resident, and a physician. Each individual's journey from layperson to skilled professional is unique and is affected by ``who they are'' at the beginning and ``who they wish to become.''           Identity formation is a dynamic process achieved through socialization; it results in individuals joining the medical community of practice. Multiple factors within and outside of the educational system affect the formation of an individual's professional identity. Each learner reacts to different factors in her or his own fashion, with the anticipated outcome being the emergence of a professional identity. However, the inherent logic in the related processes of professional identity formation and socialization may be obscured by their complexity and the large number of factors involved.           Drawing on the identity formation and socialization literature, as well as experience gained in teaching professionalism, the authors developed schematic representations of these processes. They adapted them to the medical context to guide educators as they initiate educational interventions, which aim to explicitly support professional identity formation and the ultimate goal of medical education---to ensure that medical students and residents come to ``think, act, and feel like a physician.''},
  langid = {american}
}

@article{howison2024,
  title = {Protecting Sensitive Data with Secure Data Enclaves},
  author = {Howison, Mark and Angell, Mintaka and Hastings, Justine S.},
  year = 2024,
  journal = {Digital Government: Research and Practice},
  volume = {5},
  number = {2},
  pages = {1--11},
  urldate = {2025-10-22},
  abstract = {A Secure Data Enclave is a system that allows data owners, such as governments and private firms, to control data access and ensure data security while facilitating approved uses of data by other parties. This model of data use offers additional protections and technical controls for the data owner compared to the more commonly used approach of transferring data from the owner to another party through a data sharing agreement. Under the data use model, the data owner retains full transparency and auditing over the other party's access, which can be difficult to achieve in practice with even the best legal instrument for data sharing. We describe the key technical requirements for a Secure Data Enclave, provide a reference architecture for its implementation on Amazon Web Services using managed cloud services, and describe four use cases of this architecture in partnerships with state governments to control access to sensitive administrative data.}
}

@article{liu2025,
  title = {Ensuring Privacy through Synthetic Data Generation in Education},
  author = {Liu, Qinyi and Shakya, Ronas and Jovanovic, Jelena and Khalil, Mohammad and {de la Hoz-Ruiz}, Javier},
  year = 2025,
  journal = {British Journal of Educational Technology},
  volume = {56},
  number = {3},
  pages = {1053--1073},
  issn = {1467-8535},
  urldate = {2025-10-22},
  abstract = {High-volume, high-quality and diverse datasets are crucial for advancing research in the education field. However, such datasets often contain sensitive information that poses significant privacy challenges. Traditional anonymisation techniques fail to meet the privacy standards required by regulations like GDPR, prompting the need for more robust solutions. Synthetic data have emerged as a promising privacy-preserving approach, allowing for the generation and sharing of datasets that mimic real data while ensuring privacy. Still, the application of synthetic data alone on educational datasets remains vulnerable to privacy threats such as linkage attacks. Therefore, this study explores for the first time the application of private synthetic data, which combines synthetic data with differential privacy mechanisms, in the education sector. By considering the dual needs of data utility and privacy, we investigate the performance of various synthetic data generation techniques in safeguarding sensitive educational information. Our research focuses on two key questions: the capability of these techniques to prevent privacy threats and their impact on the utility of synthetic educational datasets. Through this investigation, we aim to bridge the gap in understanding the balance between privacy and utility of advanced privacy-preserving techniques within educational contexts. Practitioner notes What is already known about this topic Traditional privacy-preserving methods for educational datasets have not proven successful in ensuring a balance of data utility and privacy. Additionally, these methods often lack empirical evaluation and/or evidence of successful application in practice. Synthetic data generation is a state-of-the-art privacy-preserving method that has been increasingly used as a substitute for real datasets for data publishing and sharing. However, recent research has demonstrated that even synthetic data are vulnerable to privacy threats. Differential privacy (DP) is the gold standard for quantifying and mitigating privacy concerns. Its combination with synthetic data, often referred to as private synthetic data, is presently the best available approach to ensuring data privacy. However, private synthetic data have not been studied in the educational domain. What this study contributes The study has applied synthetic data generation methods with DP mechanisms to educational data for the first time, provided a comprehensive report on the utility and privacy of the resulting synthetic data, and explored factors affecting the performance of synthetic data generators in the context of educational datasets. The experimental results of this study indicate that no synthetic data generator consistently outperforms others across all evaluation metrics in the examined educational datasets. Instead, different generators excel in their respective areas of proficiency, such as privacy or utility. Highlighting the potential of synthetic data generation techniques in the education sector, this work paves the way for future developments in the use of synthetic data generation for privacy-preserving educational research. Implications for practice and/or policy Key takeaways for practical application include the importance of conducting case-specific evaluations, carefully balancing data privacy with utility and exercising caution when using private synthetic data generators for high-precision computational tasks, especially in resource-limited settings as highlighted in this study. Educational researchers and practitioners can leverage synthetic data to release data without compromising student privacy, thereby promoting the development of open science and contributing to the advancement of education research. The robust privacy performance of DP-synthetic data generators may help alleviate students' privacy concerns while fostering their trust in sharing personal information. By improving the transparency and security of data sharing, DP-synthetic data generators technologies can promote student-centred data governance practices while providing a strong technical foundation for developing responsible data usage policies.},
  copyright = {{\copyright} 2025 British Educational Research Association.},
  langid = {english},
  keywords = {artificial intelligence for education,educational data mining,privacy,synthetic data}
}

@Article{ludecke2022,
  title = {easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting},
  author = {Daniel Lüdecke and Mattan S. Ben-Shachar and Indrajeet Patil and Brenton M. Wiernik and Etienne Bacher and Rémi Thériault and Dominique Makowski},
  journal = {CRAN},
  year = {2022},
  note = {R package},
  url = {https://easystats.github.io/easystats/},
}

@article{merkel2014,
  title = {Docker: {{Lightweight}} Linux Containers for Consistent Development and Deployment},
  author = {Merkel, Dirk},
  year = 2014,
  journal = {Linux journal},
  volume = {2014},
  number = {239},
  pages = {2}
}

@article{meystre2014,
  title = {Text De-Identification for Privacy Protection: {{A}} Study of Its Impact on Clinical Text Information Content},
  author = {Meystre, St{\'e}phane M and Ferr{\'a}ndez, {\'O}scar and Friedlin, F Jeffrey and South, Brett R and Shen, Shuying and Samore, Matthew H},
  year = 2014,
  journal = {Journal of Biomedical Informatics},
  volume = {50},
  pages = {142--150},
  abstract = {As more and more electronic clinical information is becoming easier to access for secondary uses such as clinical research, approaches that enable faster and more collaborative research while protecting patient privacy and confidentiality are becoming more important. Clinical text de-identification offers such advantages but is typically a tedious manual process. Automated Natural Language Processing (NLP) methods can alleviate this process, but their impact on subsequent uses of the automatically de-identified clinical narratives has only barely been investigated. In the context of a larger project to develop and investigate automated text de-identification for Veterans Health Administration (VHA) clinical notes, we studied the impact of automated text de-identification on clinical information in a stepwise manner. Our approach started with a high-level assessment of clinical notes informativeness and formatting, and ended with a detailed study of the overlap of select clinical information types and Protected Health Information (PHI). To investigate the informativeness (i.e., document type information, select clinical data types, and interpretation or conclusion) of VHA clinical notes, we used five different existing text de-identification systems. The informativeness was only minimally altered by these systems while formatting was only modified by one system. To examine the impact of de-identification on clinical information extraction, we compared counts of SNOMED-CT concepts found by an open source information extraction application in the original (i.e., not de-identified) version of a corpus of VHA clinical notes, and in the same corpus after de-identification. Only about 1.2-3\% less SNOMED-CT concepts were found in de-identified versions of our corpus, and many of these concepts were PHI that was erroneously identified as clinical information. To study this impact in more details and assess how generalizable our findings were, we examined the overlap between select clinical information annotated in the 2010 i2b2 NLP challenge corpus and automatic PHI annotations from our best-of-breed VHA clinical text de-identification system (nicknamed 'BoB'). Overall, only 0.81\% of the clinical information exactly overlapped with PHI, and 1.78\% partly overlapped. We conclude that automated text de-identification's impact on clinical information is small, but not negligible, and that improved clinical acronyms and eponyms disambiguation could significantly reduce this impact. {\copyright} 2014 Elsevier Inc.}
}

@article{mondal2025,
  title = {Copyright and Creative Commons Licenses in Scholarly Publishing: {{A}} Practical Guide for Researchers},
  author = {Mondal, Himel},
  year = 2025,
  month = sep,
  journal = {Journal of Clinical Imaging Science},
  volume = {15},
  pages = {32},
  urldate = {2025-10-23},
  abstract = {Copyright is a crucial aspect of scholarly publishing, governing the ownership, distribution, and permissible use of academic content. Traditional copyright laws grant exclusive rights to authors or publishers. In the era of open-access publication, Creative Commons (CC) licenses offer the flexibility to share scholarly work more openly while maintaining proper attribution. Understanding these licensing options is essential for researchers. This article explores the fundamental concepts of copyright, licensing, and CC in the context of scholarly publishing. It briefly explains how to search for copyright and licensing information on an article, properly attribute credit, and obtain permission for content reuse from the copyright holder. Failure to comply with copyright regulations can result in consequences such as legal disputes, financial penalties, and reputational damage. Hence, an understanding and responsible application of copyright and licensing principles are therefore essential for ethical and legally compliant scholarly communication.}
}

@article{ness2007,
  title = {Influence of the {{HIPAA}} Privacy Rule on Health Research},
  author = {Ness, Roberta B.},
  year = 2007,
  month = nov,
  journal = {JAMA},
  volume = {298},
  number = {18},
  pages = {2164--2170},
  issn = {0098-7484},
  urldate = {2025-10-22},
  abstract = {ContextAnecdotal reports suggest that the Health Insurance Portability and Accountability Act Privacy Rule (HIPAA Privacy Rule) may be affecting health research in the United States.ObjectiveTo survey epidemiologists about their experiences with the HIPAA Privacy Rule.Design, Setting, and ParticipantsThirteen societies of epidemiology distributed a national Web-based survey; 2805 respondents accessed the survey Web site and 1527 eligible professionals anonymously answered questions.Main Outcome MeasuresResponses related influences such as research delays and added cost after Privacy Rule implementation, frequency and type of Privacy Rule--related institutional review board modifications, level of difficulty obtaining deidentified data and waivers, experiences with multisite studies, and perceived participant privacy benefits under the rule. Respondents ranked their perceptions of Privacy Rule influence on 5-point Likert scales.ResultsA total of 875 (67.8\%) respondents reported that the HIPAA Privacy Rule has made research more difficult at a level of 4 to 5 on a Likert scale, in which 5 indicates a great deal of added cost and time to study completion. A total of 684 (52.1\%) of respondents identified a ``most affected'' protocol. Respondents indicated that the proportion of institutional review board applications in which the Privacy Rule had a negative influence on human subjects (participants) protection was significantly greater than the proportion in which it had a positive influence (P~\&lt;~.001).ConclusionIn this national survey of clinical scientists, only a quarter perceived that the rule has enhanced participants' confidentiality and privacy, whereas the HIPAA Privacy Rule was perceived to have a substantial, negative influence on the conduct of human subjects health research, often adding uncertainty, cost, and delay.}
}

@article{nicholls2016,
  title = {Reporting Transparency: Making the Ethical Mandate Explicit},
  shorttitle = {Reporting Transparency},
  author = {Nicholls, Stuart G. and Langan, Sin{\'e}ad M. and Benchimol, Eric I. and Moher, David},
  year = 2016,
  month = mar,
  journal = {BMC Medicine},
  volume = {14},
  number = {1},
  pages = {44},
  issn = {1741-7015},
  urldate = {2025-10-22},
  abstract = {Improving the transparency and quality of reporting in biomedical research is considered ethically important; yet, this is often based on practical reasons such as the facilitation of peer review. Surprisingly, there has been little explicit discussion regarding the ethical obligations that underpin reporting guidelines. In this commentary, we suggest a number of ethical drivers for the improved reporting of research. These ethical drivers relate to researcher integrity as well as to the benefits derived from improved reporting such as the fair use of resources, minimizing risk of harms, and maximizing benefits. Despite their undoubted benefit to reporting completeness, questions remain regarding the extent to which reporting guidelines can influence processes beyond publication, including researcher integrity or the uptake of scientific research findings into policy or practice. Thus, we consider investigation on the effects of reporting guidelines an important step in providing evidence of their benefits.},
  langid = {english},
  keywords = {Moral obligations,Publication bias,Research personnel/ethics,Research waste,Social values,Standards}
}

@article{nosek2019,
  title = {Preregistration Is Hard, and Worthwhile},
  author = {Nosek, Brian A. and Beck, Emorie D. and Campbell, Lorne and Flake, Jessica K. and Hardwicke, Tom E. and Mellor, David T. and {van 't Veer}, Anna E. and Vazire, Simine},
  year = 2019,
  journal = {Trends in Cognitive Sciences},
  volume = {23},
  number = {10},
  pages = {815--818},
  issn = {1364-6613},
  abstract = {Preregistration clarifies the distinction between planned and unplanned research by reducing unnoticed flexibility. This improves credibility of findings and calibration of uncertainty. However, making decisions before conducting analyses requires practice. During report writing, respecting both what was planned and what actually happened requires good judgment and humility in making claims.},
  keywords = {confirmatory research,exploratory research,preregistration,reproducibility,transparency}
}

@article{sandve2013,
  title = {Ten Simple Rules for Reproducible Computational Research},
  author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
  year = 2013,
  journal = {PLOS Computational Biology},
  volume = {9},
  number = {10},
  pages = {e1003285},
  issn = {1553-7358},
  langid = {english},
  keywords = {Archives,Computer and information sciences,Computer applications,Genome analysis,Habits,Replication studies,Reproducibility,Source code}
}

@misc{scheidegger2025,
  title = {Quarto},
  author = {Scheidegger, Carlos and Woodhull, Gordon and Dervieux, Christophe and Teague, Charles and Allaire, J J and Xie, Yihui},
  year = 2025,
  url = {https://quarto.org},
  howpublished = {Posit, PBC}
}

@article{simmons2021,
  title = {Pre-Registration Is a Game Changer. {{But}}, like Random Assignment, It Is Neither Necessary nor Sufficient for Credible Science},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  year = 2021,
  journal = {Journal of Consumer Psychology},
  volume = {31},
  number = {1},
  pages = {177--180},
  issn = {1532-7663},
  urldate = {2025-10-22},
  abstract = {We identify 15 claims Pham and Oh (2020) make to argue against pre-registration. We agree with 7 of the claims, but think that none of them justify delaying the encouragement and adoption of pre-registration. Moreover, while the claim they make in their title is correct---pre-registration is neither necessary nor sufficient for a credible science---this is also true of many our science's most valuable tools, such as random assignment. Indeed, both random assignment and pre-registration lead to more credible research. Pre-registration is a game changer.},
  copyright = {{\copyright} 2021 Society for Consumer Psychology},
  langid = {english}
}

@article{strand2025,
  title = {Error Tight: Exercises for Lab Groups to Prevent Research Mistakes},
  shorttitle = {Error Tight},
  author = {Strand, Julia F.},
  year = 2025,
  journal = {Psychological Methods},
  volume = {30},
  number = {2},
  pages = {416--424},
  issn = {1082-989X},
  urldate = {2025-04-18},
  abstract = {Scientists, being human, make mistakes. We transcribe things incorrectly, we make errors in our code, and we intend to do things and then forget. The consequences of errors in research may be as minor as wasted time and annoyance, but may be as severe as losing months of work or having to retract an article. The purpose of this tutorial is to help lab groups identify places in their research workflow where errors may occur and identify ways to avoid them. To do this, this article applies concepts from human factors research on how to create lab cultures and workflows that are intended to minimize errors. This article does not provide a one-size-fits-all set of guidelines for specific practices to use (e.g., one platform on which to backup data); instead, it gives examples of ways that mistakes can occur in research along with recommendations for systems that avoid and detect them. This tutorial is intended to be used as a discussion prompt prior to a lab meeting to help researchers reflect on their own processes and implement safeguards to avoid future errors. (PsycInfo Database Record (c) 2025 APA, all rights reserved) (Source: journal abstract) Translational Abstract: Everyone makes mistakes. In science, mistakes can occur in many ways: Researchers may transcribe things incorrectly, make typos when writing code to analyze data, forget to do something they intended to, and so forth. These mistakes may simply waste time or require redoing work, but in more serious cases, they can ruin an experiment or lead to false conclusions. However, learning how to avoid errors in research isn't a standard part of training. This tutorial is intended to help lab groups identify places in the research process where errors may occur and identify ways to avoid them. To do so, this article draws on lessons from high-risk fields such as aviation, surgery, and construction, all of which have developed explicit, practical strategies to reduce mistakes on the job. This tutorial is intended to be used as a discussion prompt before a lab meeting to help researchers reflect on their own processes and implement safeguards to avoid future errors. (PsycInfo Database Record (c) 2025 APA, all rights reserved)},
  copyright = {{\copyright} 2023, American Psychological Association},
  langid = {english},
  keywords = {Concepts,Data Sets,Errors,Experimental Laboratories,Forgetting,Methodology,Scientists}
}

@article{tackett2017,
  title = {It's Time to Broaden the Replicability Conversation: {{Thoughts}} for and from Clinical Psychological Science},
  author = {Tackett, Jennifer L and Lilienfeld, Scott O and Patrick, Christopher J and Johnson, Sheri L and Krueger, Robert F and Miller, Joshua D and Oltmanns, Thomas F and Shrout, Patrick E},
  year = 2017,
  journal = {Perspectives on Psychological Science},
  volume = {12},
  number = {5},
  pages = {742--756},
  issn = {1745691613489},
  abstract = {Psychology is in the early stages of examining a crisis of replicability stemming from several high-profile failures to replicate studies in experimental psychology. This important conversation has largely been focused on social psychology, with some active participation from cognitive psychology. Nevertheless, several other major domains of psychological science---including clinical science---have remained insulated from this discussion. The goals of this article are to (a) examine why clinical psychology and allied fields, such as counseling and school psychology, have not been central participants in the replicability conversation; (b) review concerns and recommendations that are less (or more) applicable to or appropriate for research in clinical psychology and allied fields; and (c) generate take-home messages for scholars and consumers of the literature in clinical psychology and allied fields, as well as reviewers, editors, and colleagues from other areas of psychological science.}
}

@book{turrell2025,
  title = {Python for {{Data Science}}},
  author = {Turrell, Arthur and Monticone, Pietro and Akyol, Zeki and Holman, Josh and Huang, Yiben},
  year = 2025,
  url = {https://aeturrell.github.io/python4DS/}
}

@misc{ushey2025,
  title = {Renv: {{Project Environments}}},
  author = {Ushey, Kevin and Wickham, Hadley},
  year = 2025,
  annotation = {R package version 1.1.4}, 
  url = {https://rstudio.github.io/renv}
}

@article{vantilinpress,
  title = {Open Science Training in {{APA-accredited}} Clinical Psychology Programs: {{A}} Registered Report},
  author = {Van Til, Kaela and Phillips, Nathaniel and Du, Tianwei and Rose, Leigha and Miller, Joshua and Lynam, Donald},
  year = {in press},
  journal = {Clinical Psychological Science}
}

@book{wickham2023,
  title = {R for {{Data Science}}},
  author = {Wickham, Hadley and {\c C}etinkaya-Rundel, Mine and Grolemund, Garrett},
  year = 2023,
  edition = {2nd},
  publisher = {O'Reilly Media},
  url = {https://r4ds.hadley.nz/}
}

@incollection{wiley2014,
  title = {Open Educational Resources: A Review of the Literature},
  shorttitle = {Open Educational Resources},
  booktitle = {Handbook of Research on Educational Communications and Technology},
  author = {Wiley, David and Bliss, T. J. and McEwen, Mary},
  editor = {Spector, J. Michael and Merrill, M. David and Elen, Jan and Bishop, M. J.},
  year = 2014,
  pages = {781--789},
  publisher = {Springer},
  address = {New York, NY},
  urldate = {2025-10-22},
  abstract = {This chapter begins by reviewing the many definitions of the term open educational resources and concludes by discussing challenges and opportunities for the approach. Open educational resources (OER) are educational materials either licensed under an open copyright license or in the public domain. Neither the term ``open educational resources'' nor the term ``open'' itself has an agreed upon definition in the literature. Research regarding open educational resources focuses on methods of producing OER, methods of sharing OER, and the benefits of OER. Significant issues relating to OER remain unresolved, including business model and discovery problems.},
  isbn = {978-1-4614-3185-5},
  langid = {english},
  keywords = {Affordability,Open educational resources,Remix,Reuse}
}

@article{mabile2025,
	title = {Recommendations on open science rewards and incentives: guidance for multiple stakeholders in research},
	author = {Mabile, Laurence and Shmagun, Hanna and Erdmann, Christopher and Cambon-Thomsen, Anne and Thomsen, Mogens and Grattarola, Florencia},
	year = {2025},
	date = {2025},
	journal = {Data Science Journal},
	pages = {1--9},
	volume = {24},
	number = {15},
	langid = {en}
}

@article{ali-khan2017,
	title = {Motivating participation in open science by examining researcher incentives},
	author = {Ali-Khan, Sarah E and Harris, Liam W and Gold, E Richard},
	editor = {Rodgers, Peter A},
	year = {2017},
	date = {2017},
	journal = {eLife},
	pages = {e29319},
	volume = {6},
	doi = {10.7554/eLife.29319}
}

@article{perkel2018,
	title = {Why Jupyter is data scientists{\textquoteright} computational notebook of choice},
	author = {Perkel, Jeffrey M.},
	year = {2018},
	date = {2018},
	journal = {Nature},
	pages = {145--146},
	volume = {563},
	number = {7729},
	langid = {en}
}

@article{cohen2019,
	title = {Fear of fraudulence: graduate school program environments and the impostor phenomenon},
	author = {Cohen, Emma D. and McConnell, Will R.},
	year = {2019},
	date = {2019},
	journal = {The Sociological Quarterly},
	pages = {457--478},
	volume = {60},
	number = {3},
	note = {Publisher: Routledge
{\_}eprint: https://doi.org/10.1080/00380253.2019.1580552}
}
